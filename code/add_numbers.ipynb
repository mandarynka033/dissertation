{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rue0CyhGHGEm"
      },
      "source": [
        "## Library import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "! pip install transformers\n",
        "! pip install --upgrade gensim\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPrmWcGUHJZy",
        "outputId": "cd32c759-c943-47af-ead3-18bd92547800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI6LZ1BCHGEq"
      },
      "outputs": [],
      "source": [
        "# Language processing\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# System\n",
        "import sys\n",
        "path_smt = '/content/drive/MyDrive/dis/'\n",
        "sys.path.append(path_smt)\n",
        "\n",
        "# Data preprocessing\n",
        "from preprocessing import *\n",
        "import pandas as pd\n",
        "np.random.seed(1)\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Statistical tools\n",
        "import scipy.stats as stat\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Word2vec\n",
        "import gensim\n",
        "import gensim.downloader\n",
        "from gensim.models import Word2Vec\n",
        "google_news_vectors = gensim.downloader.load('word2vec-google-news-300')\n",
        "\n",
        "# Glove\n",
        "embeddings_dict = {}\n",
        "with open(path_smt + \"glove.6B.50d.txt\", 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL8J4CbwHGEr"
      },
      "source": [
        "## Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A97x22FHGEs"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(path_smt+\"SMTeuroparl.train.tsv\", sep='\\t', encoding='utf-8', header = None, \n",
        "                 names = ['sim', 'sent1', 'sent2'])\n",
        "data[\"sim01\"] = (data[\"sim\"]-min(data[\"sim\"]))/(max(data[\"sim\"])-min(data[\"sim\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "ElL8HX8gxZQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"sent1\", data)\n",
        "preprocess(\"sent2\", data)\n",
        "# Last preprocessing step of tokenisation\n",
        "data[\"sent1_stop\"] = data.apply(lambda row: nltk.word_tokenize(row['sent1_punct']), axis=1)\n",
        "data[\"sent2_stop\"] = data.apply(lambda row: nltk.word_tokenize(row['sent2_punct']), axis=1)"
      ],
      "metadata": {
        "id": "kkgfkq67NRkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Out-of-vocabulary words and numbers addition"
      ],
      "metadata": {
        "id": "9e-aKbwKxcce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the whole vocabulary\n",
        "sent1_set = set(' '.join(data['sent1_punct']).split())\n",
        "sent2_set = set(' '.join(data['sent2_punct']).split())\n",
        "all_words = sent1_set.union(sent2_set)\n",
        "\n",
        "# Dictionary keys to find missing keys\n",
        "google_lst = google_news_vectors.index_to_key\n",
        "glove_keys = embeddings_dict.keys()\n",
        "add_google = all_words.difference(google_lst)\n",
        "add_glove = all_words.difference(glove_keys)"
      ],
      "metadata": {
        "id": "cw_GDb8bNWzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add numbers for Glove\n",
        "for wrd in add_glove:\n",
        "    if wrd.isnumeric():\n",
        "        vec_nb = np.zeros((len(wrd)-2, 50))\n",
        "        vec_nb[0, :] = embeddings_dict[str(int(wrd[-3:]))]\n",
        "        for k in range(3, len(wrd)):\n",
        "            nb = int(wrd[-(k+1):]) - int(wrd) % 10**(k)\n",
        "            if str(nb) in embeddings_dict:\n",
        "                vec_nb[k-2, :] = embeddings_dict[str(nb)]\n",
        "        embeddings_dict[wrd] = np.average(vec_nb, axis = 0)\n",
        "    # else:\n",
        "    # embeddings_dict[wrd] = np.random.normal(size = 50)\n",
        "        \n",
        "# Add numbers for Google\n",
        "for wrd in add_google:\n",
        "    if wrd.isnumeric():\n",
        "        vec_nb = np.zeros((len(wrd), 300))\n",
        "        for k in range(len(wrd)):\n",
        "            vec_nb[k, :] = google_news_vectors[wrd[k]]\n",
        "        google_news_vectors[wrd] = np.average(vec_nb, axis = 0)                   \n",
        "    # else:\n",
        "    # google_news_vectors[wrd] = np.random.normal(size = 300)"
      ],
      "metadata": {
        "id": "BLYXJyHQOPeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syplQT3mHGEt"
      },
      "source": [
        "## Vector average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNbmxl5OHGEt"
      },
      "outputs": [],
      "source": [
        "# Compute vector average for two sentences\n",
        "def comp_aver(var,  diction, j, base_emb):\n",
        "  # Set vector dimensions based on the word embeddings in use\n",
        "    if base_emb == \"glove\":\n",
        "        len_emb = 50\n",
        "    else:\n",
        "        len_emb = 300\n",
        "\n",
        "# Empty vector for word embeddings\n",
        "    word_vectors = np.zeros((len_emb, len(var[j])))\n",
        "    for i in range(len(var[j])):\n",
        "        wrd = var[j][i]\n",
        "        # Obtain specific word embedding\n",
        "        word_vectors[:, i] = diction[wrd]\n",
        "#             Return the average of all word vectors\n",
        "    return(np.sum(word_vectors, axis = 1)/len(var[j]))\n",
        "\n",
        "# Compute vector average for dataframe\n",
        "def add_stats(dt1, dt2, emb, dicti):\n",
        "    sims = np.zeros(len(dt1))\n",
        "    for jj in range(len(dt1)):\n",
        "        avg_vec1 = comp_aver(dt1, base_emb = emb, diction = dicti, j = jj)\n",
        "        avg_vec2 = comp_aver(dt2, base_emb = emb, diction = dicti, j = jj)\n",
        "\n",
        "#         Compute cosine distance\n",
        "        sims[jj] = 1 - spatial.distance.cosine(avg_vec1, avg_vec2)\n",
        "\n",
        "    # Adding the calculated similarity to the dataframe\n",
        "    data.loc[:, emb + \"_sim\"] = sims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCcNNe4MHGEw"
      },
      "outputs": [],
      "source": [
        "add_stats(data.sent1_stop, data.sent2_stop, emb = \"google\", dicti = google_news_vectors)\n",
        "add_stats(data.sent1_stop, data.sent2_stop, emb = \"glove\", dicti = embeddings_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPuI0ATHGEw"
      },
      "source": [
        "## WMD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv-JaIxaHGEw"
      },
      "outputs": [],
      "source": [
        "sims_glove = np.zeros(len(data))\n",
        "sims_google = np.zeros(len(data))\n",
        "# Calculating WMD\n",
        "for i in range(len(data)):\n",
        "    sims_glove[i] = wmdist(embeddings_dict, data.sent1_stop[i], data.sent2_stop[i])\n",
        "    sims_google[i] = wmdist(google_news_vectors, data.sent1_stop[i], data.sent2_stop[i])\n",
        "    \n",
        "# Adding the inverted distance to dataframe\n",
        "data[\"wmd_google\"] = 1/(1+sims_google)\n",
        "data[\"wmd_glove\"] = 1/(1+sims_glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7IogbOZHGEx"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVMmc4_mHGEy",
        "outputId": "64b23c25-996a-40d9-f5de-594d4d2b41f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation for average Word2vec: 0.4194033766042279\n",
            "Correlation for average Glove: 0.6496622253231086\n"
          ]
        }
      ],
      "source": [
        "print(\"Correlation for average Word2vec:\", stat.pearsonr(data[\"google_sim\"], data[\"sim\"])[0])\n",
        "print(\"Correlation for average Glove:\", stat.pearsonr(data[\"glove_sim\"], data[\"sim\"])[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4hz-OeBHGEy",
        "outputId": "aee810e2-d437-4cb4-b6e3-d18a9a97a244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation for wmd nbs Word2vec: 0.5271859140500685\n",
            "Correlation for wmd nbs Glove: 0.6002472882634206\n"
          ]
        }
      ],
      "source": [
        "print(\"Correlation for wmd Word2vec:\", stat.pearsonr(data[\"wmd_google\"], data[\"sim\"])[0])\n",
        "print(\"Correlation for wmd Glove:\", stat.pearsonr(data[\"wmd_glove\"], data[\"sim\"])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Investigation of what contexts numbers occur in"
      ],
      "metadata": {
        "id": "jBrxGWIAynBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvL8ioh-HGEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5988d104-e48d-43ba-d782-595f6d6745e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0                      \n",
            "match     0     1     2    3    4\n",
            "11        8   NaN   NaN  NaN  NaN\n",
            "18       11   NaN   NaN  NaN  NaN\n",
            "24       24   NaN   NaN  NaN  NaN\n",
            "30       16  2000   NaN  NaN  NaN\n",
            "38      299     2   NaN  NaN  NaN\n",
            "43      299     2   NaN  NaN  NaN\n",
            "54      150   NaN   NaN  NaN  NaN\n",
            "59        1   NaN   NaN  NaN  NaN\n",
            "72       16  2000   NaN  NaN  NaN\n",
            "77      150   NaN   NaN  NaN  NaN\n",
            "92      500     3     0   39  924\n",
            "114    2001   NaN   NaN  NaN  NaN\n",
            "122       7   NaN   NaN  NaN  NaN\n",
            "126       8   NaN   NaN  NaN  NaN\n",
            "128    1996   NaN   NaN  NaN  NaN\n",
            "134     250   120   NaN  NaN  NaN\n",
            "148    2001   NaN   NaN  NaN  NaN\n",
            "149     250   120   NaN  NaN  NaN\n",
            "162     272   NaN   NaN  NaN  NaN\n",
            "178       8   NaN   NaN  NaN  NaN\n",
            "180       5  0794  2000  NaN  NaN\n",
            "186     272   NaN   NaN  NaN  NaN\n",
            "202       2    06     3  NaN  NaN\n",
            "204       6  0886    00  NaN  NaN\n",
            "205    1996   NaN   NaN  NaN  NaN\n",
            "233    2001   NaN   NaN  NaN  NaN\n",
            "243     299     2   NaN  NaN  NaN\n",
            "249       5  0794  2000  NaN  NaN\n",
            "258       6  0886    00  NaN  NaN\n",
            "269     299     2   NaN  NaN  NaN\n",
            "270       2    06     3  NaN  NaN\n",
            "276      15   NaN   NaN  NaN  NaN\n",
            "280      11   NaN   NaN  NaN  NaN\n",
            "286       5  0794  2000  NaN  NaN\n",
            "288     272   NaN   NaN  NaN  NaN\n",
            "292      15   NaN   NaN  NaN  NaN\n",
            "294     250   120   NaN  NaN  NaN\n",
            "299       1   NaN   NaN  NaN  NaN\n",
            "314       8   NaN   NaN  NaN  NaN\n",
            "319       7   NaN   NaN  NaN  NaN\n",
            "322       5  0794  2000  NaN  NaN\n",
            "323      15   NaN   NaN  NaN  NaN\n",
            "330     150   NaN   NaN  NaN  NaN\n",
            "333      16  2000   NaN  NaN  NaN\n",
            "338     299     2   NaN  NaN  NaN\n",
            "342     250   120   NaN  NaN  NaN\n",
            "351       1   NaN   NaN  NaN  NaN\n",
            "354     299     2   NaN  NaN  NaN\n",
            "367    2001   NaN   NaN  NaN  NaN\n",
            "374      16  2000   NaN  NaN  NaN\n",
            "382     299     2   NaN  NaN  NaN\n",
            "385       5  0794  2000  NaN  NaN\n",
            "388      11   NaN   NaN  NaN  NaN\n",
            "394    2001   NaN   NaN  NaN  NaN\n",
            "410       1   NaN   NaN  NaN  NaN\n",
            "412     272   NaN   NaN  NaN  NaN\n",
            "415    2001   NaN   NaN  NaN  NaN\n",
            "422       1   NaN   NaN  NaN  NaN\n",
            "429       2    06     3  NaN  NaN\n",
            "430     150   NaN   NaN  NaN  NaN\n",
            "433       8   NaN   NaN  NaN  NaN\n",
            "435      11   NaN   NaN  NaN  NaN\n",
            "436    1996   NaN   NaN  NaN  NaN\n",
            "443       7   NaN   NaN  NaN  NaN\n",
            "445      11   NaN   NaN  NaN  NaN\n",
            "449     272   NaN   NaN  NaN  NaN\n",
            "460      15   NaN   NaN  NaN  NaN\n",
            "471     150   NaN   NaN  NaN  NaN\n",
            "480       5  0794  2000  NaN  NaN\n",
            "484      15   NaN   NaN  NaN  NaN\n",
            "488     150   NaN   NaN  NaN  NaN\n",
            "493      11   NaN   NaN  NaN  NaN\n",
            "500     250   120   NaN  NaN  NaN\n",
            "505    2001   NaN   NaN  NaN  NaN\n",
            "508    1996   NaN   NaN  NaN  NaN\n",
            "532      11   NaN   NaN  NaN  NaN\n",
            "533       7   NaN   NaN  NaN  NaN\n",
            "547      15   NaN   NaN  NaN  NaN\n",
            "552       1   NaN   NaN  NaN  NaN\n",
            "568      15   NaN   NaN  NaN  NaN\n",
            "589       7   NaN   NaN  NaN  NaN\n",
            "613       6  0886    00  NaN  NaN\n",
            "620     150   NaN   NaN  NaN  NaN\n",
            "624       6  0886    00  NaN  NaN\n",
            "627      16  2000   NaN  NaN  NaN\n",
            "639      16  2000   NaN  NaN  NaN\n",
            "640       1   NaN   NaN  NaN  NaN\n",
            "644     250   120   NaN  NaN  NaN\n",
            "653    1996   NaN   NaN  NaN  NaN\n",
            "659       5  0794  2000  NaN  NaN\n",
            "660    1996   NaN   NaN  NaN  NaN\n",
            "674       7   NaN   NaN  NaN  NaN\n",
            "680       7   NaN   NaN  NaN  NaN\n",
            "681       2    06     3  NaN  NaN\n",
            "695     250   120   NaN  NaN  NaN\n",
            "707       8   NaN   NaN  NaN  NaN\n",
            "709       6  0886    00  NaN  NaN\n",
            "710    1996   NaN   NaN  NaN  NaN\n",
            "716      16  2000   NaN  NaN  NaN\n",
            "725       8   NaN   NaN  NaN  NaN\n"
          ]
        }
      ],
      "source": [
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "  print(data.sent1.str.extractall(r\"(\\d+)\").unstack())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "  print(data.sent2.str.extractall(r\"(\\d+)\").unstack())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoAqspKd1l6v",
        "outputId": "458b005f-cdca-4079-df26-b5e625a1f85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0                      \n",
            "match     0     1     2    3    4\n",
            "11        8   NaN   NaN  NaN  NaN\n",
            "18       11   NaN   NaN  NaN  NaN\n",
            "24       57    24   NaN  NaN  NaN\n",
            "30       16  2000   NaN  NaN  NaN\n",
            "38      299     2   NaN  NaN  NaN\n",
            "43      299     2   NaN  NaN  NaN\n",
            "54      150   NaN   NaN  NaN  NaN\n",
            "59        1   NaN   NaN  NaN  NaN\n",
            "72       16  2000   NaN  NaN  NaN\n",
            "77      150   NaN   NaN  NaN  NaN\n",
            "92        6     0    41    1  498\n",
            "114    2001   NaN   NaN  NaN  NaN\n",
            "122       7   NaN   NaN  NaN  NaN\n",
            "126       8   NaN   NaN  NaN  NaN\n",
            "128    1996   NaN   NaN  NaN  NaN\n",
            "134     250   120   NaN  NaN  NaN\n",
            "148    2001   NaN   NaN  NaN  NaN\n",
            "149     250   120   NaN  NaN  NaN\n",
            "162     272   NaN   NaN  NaN  NaN\n",
            "178       8   NaN   NaN  NaN  NaN\n",
            "180       5  0794  2000  NaN  NaN\n",
            "186     272   NaN   NaN  NaN  NaN\n",
            "202      14    06     3  NaN  NaN\n",
            "204       6  0886    00  NaN  NaN\n",
            "205    1996   NaN   NaN  NaN  NaN\n",
            "233    2001   NaN   NaN  NaN  NaN\n",
            "243     299     2   NaN  NaN  NaN\n",
            "249       5  0794  2000  NaN  NaN\n",
            "258       6  0886    00  NaN  NaN\n",
            "269     299     2   NaN  NaN  NaN\n",
            "270      14    06     3  NaN  NaN\n",
            "280      11   NaN   NaN  NaN  NaN\n",
            "286       5  0794  2000  NaN  NaN\n",
            "288     272   NaN   NaN  NaN  NaN\n",
            "292      15   NaN   NaN  NaN  NaN\n",
            "294     250   120   NaN  NaN  NaN\n",
            "299       1   NaN   NaN  NaN  NaN\n",
            "314       8   NaN   NaN  NaN  NaN\n",
            "319       7   NaN   NaN  NaN  NaN\n",
            "322       5  0794  2000  NaN  NaN\n",
            "330     150   NaN   NaN  NaN  NaN\n",
            "333      16  2000   NaN  NaN  NaN\n",
            "338     299     2   NaN  NaN  NaN\n",
            "342     250   120   NaN  NaN  NaN\n",
            "351       1   NaN   NaN  NaN  NaN\n",
            "354     299     2   NaN  NaN  NaN\n",
            "367    2001   NaN   NaN  NaN  NaN\n",
            "374      16  2000   NaN  NaN  NaN\n",
            "382     299     2   NaN  NaN  NaN\n",
            "385       5  0794  2000  NaN  NaN\n",
            "388      11   NaN   NaN  NaN  NaN\n",
            "394    2001   NaN   NaN  NaN  NaN\n",
            "410       1   NaN   NaN  NaN  NaN\n",
            "412     272   NaN   NaN  NaN  NaN\n",
            "415    2001   NaN   NaN  NaN  NaN\n",
            "422       1   NaN   NaN  NaN  NaN\n",
            "429       3   NaN   NaN  NaN  NaN\n",
            "430     150   NaN   NaN  NaN  NaN\n",
            "433       8   NaN   NaN  NaN  NaN\n",
            "435      11   NaN   NaN  NaN  NaN\n",
            "436    1996   NaN   NaN  NaN  NaN\n",
            "443       7   NaN   NaN  NaN  NaN\n",
            "445      11   NaN   NaN  NaN  NaN\n",
            "449     272   NaN   NaN  NaN  NaN\n",
            "471     150   NaN   NaN  NaN  NaN\n",
            "480       5  0794  2000  NaN  NaN\n",
            "488     150   NaN   NaN  NaN  NaN\n",
            "493      11   NaN   NaN  NaN  NaN\n",
            "500     250   120   NaN  NaN  NaN\n",
            "505    2001   NaN   NaN  NaN  NaN\n",
            "508    1996   NaN   NaN  NaN  NaN\n",
            "532      11   NaN   NaN  NaN  NaN\n",
            "533       7   NaN   NaN  NaN  NaN\n",
            "552       1   NaN   NaN  NaN  NaN\n",
            "589       7   NaN   NaN  NaN  NaN\n",
            "613       6  0886    00  NaN  NaN\n",
            "620     150   NaN   NaN  NaN  NaN\n",
            "624       6  0886    00  NaN  NaN\n",
            "627      16  2000   NaN  NaN  NaN\n",
            "639      16  2000   NaN  NaN  NaN\n",
            "640       1   NaN   NaN  NaN  NaN\n",
            "644     250   120   NaN  NaN  NaN\n",
            "653    1996   NaN   NaN  NaN  NaN\n",
            "659       5  0794  2000  NaN  NaN\n",
            "660    1996   NaN   NaN  NaN  NaN\n",
            "674       7   NaN   NaN  NaN  NaN\n",
            "680       7   NaN   NaN  NaN  NaN\n",
            "681      14    06     3  NaN  NaN\n",
            "695     250   120   NaN  NaN  NaN\n",
            "707       8   NaN   NaN  NaN  NaN\n",
            "709       6  0886    00  NaN  NaN\n",
            "710    1996   NaN   NaN  NaN  NaN\n",
            "716      16  2000   NaN  NaN  NaN\n",
            "725       8   NaN   NaN  NaN  NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentences with numbers."
      ],
      "metadata": {
        "id": "VX6LBANDyuVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.sent1.str.contains(r\"\\d+\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oTjK9RBc2Rcl",
        "outputId": "347bf5fa-de74-4bd8-a03e-573698e8401f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sim                                              sent1  \\\n",
              "11   4.2  He will stand trial on 8 January on charges of...   \n",
              "18   4.8  Mr President, the Commission' s attitude to th...   \n",
              "24   5.0  Fifty-seven senators, including 24 Republicans...   \n",
              "30   4.4  Reiterating the calls made by the European Par...   \n",
              "38   4.0  As a matter of urgency, therefore, the staff c...   \n",
              "..   ...                                                ...   \n",
              "707  3.8  He will stand trial on 8 January on charges of...   \n",
              "709  5.0                      Question No 6 by (H-0886/00):   \n",
              "710  3.8  As long ago as 1996 the European Parliament ca...   \n",
              "716  4.4  Reiterating the calls made by the European Par...   \n",
              "725  3.6  He will stand trial on 8 January on charges of...   \n",
              "\n",
              "                                                 sent2  sim01  \\\n",
              "11   It passes in lawsuit next on January 8. It is ...   0.84   \n",
              "18   Mr President, we can see the Commission's posi...   0.96   \n",
              "24   Of those who signed the letter, 57 are senator...   1.00   \n",
              "30   As the European Parliament, in its resolution ...   0.88   \n",
              "38   Therefore, it is urgent that the personnel of ...   0.80   \n",
              "..                                                 ...    ...   \n",
              "707  It happening in trial on 8 January. he is accu...   0.76   \n",
              "709                      Question No 6 by (H-0886/00):   1.00   \n",
              "710  In 1996, the European Parliament is in favour ...   0.76   \n",
              "716  As the European Parliament called for in its r...   0.88   \n",
              "725  It crosses the 8 January of this year. it is t...   0.72   \n",
              "\n",
              "                                           sent1_punct  \\\n",
              "11   stand trial 8 january charges attended meeting...   \n",
              "18   mr president commission attitude right access ...   \n",
              "24   fiftyseven senators including 24 republicans s...   \n",
              "30   reiterating calls made european parliament res...   \n",
              "38   matter urgency therefore staff complement inte...   \n",
              "..                                                 ...   \n",
              "707  stand trial 8 january charges attended meeting...   \n",
              "709                              question no 6 h088600   \n",
              "710  long ago 1996 european parliament came favor b...   \n",
              "716  reiterating calls made european parliament res...   \n",
              "725  stand trial 8 january charges attended meeting...   \n",
              "\n",
              "                                           sent2_punct  \\\n",
              "11   passes lawsuit next january 8 reproached taken...   \n",
              "18   mr president see commission position terms pub...   \n",
              "24   signed letter 57 senators including 24 republi...   \n",
              "30   european parliament resolution 16 march 2000 i...   \n",
              "38   therefore urgent personnel interservice group ...   \n",
              "..                                                 ...   \n",
              "707  happening trial 8 january accused taking part ...   \n",
              "709                              question no 6 h088600   \n",
              "710  1996 european parliament favor ban use europea...   \n",
              "716  european parliament called resolution 16 march...   \n",
              "725  crosses 8 january year union tunisian opponent...   \n",
              "\n",
              "                                            sent1_stop  \\\n",
              "11   [stand, trial, 8, january, charges, attended, ...   \n",
              "18   [mr, president, commission, attitude, right, a...   \n",
              "24   [fiftyseven, senators, including, 24, republic...   \n",
              "30   [reiterating, calls, made, european, parliamen...   \n",
              "38   [matter, urgency, therefore, staff, complement...   \n",
              "..                                                 ...   \n",
              "707  [stand, trial, 8, january, charges, attended, ...   \n",
              "709                         [question, no, 6, h088600]   \n",
              "710  [long, ago, 1996, european, parliament, came, ...   \n",
              "716  [reiterating, calls, made, european, parliamen...   \n",
              "725  [stand, trial, 8, january, charges, attended, ...   \n",
              "\n",
              "                                            sent2_stop  google_sim  glove_sim  \\\n",
              "11   [passes, lawsuit, next, january, 8, reproached...    0.923275   0.952771   \n",
              "18   [mr, president, see, commission, position, ter...    0.807435   0.992223   \n",
              "24   [signed, letter, 57, senators, including, 24, ...    0.518123   0.946429   \n",
              "30   [european, parliament, resolution, 16, march, ...    0.966281   0.991883   \n",
              "38   [therefore, urgent, personnel, interservice, g...    0.604373   0.940241   \n",
              "..                                                 ...         ...        ...   \n",
              "707  [happening, trial, 8, january, accused, taking...    0.949604   0.951461   \n",
              "709                         [question, no, 6, h088600]    1.000000   1.000000   \n",
              "710  [1996, european, parliament, favor, ban, use, ...    0.802647   0.969966   \n",
              "716  [european, parliament, called, resolution, 16,...    0.976658   0.993452   \n",
              "725  [crosses, 8, january, year, union, tunisian, o...    0.896926   0.893717   \n",
              "\n",
              "     wmd_google  wmd_glove  \n",
              "11     0.690925   0.797823  \n",
              "18     0.744582   0.852462  \n",
              "24     0.875752   0.898666  \n",
              "30     0.794706   0.897016  \n",
              "38     0.669141   0.747385  \n",
              "..          ...        ...  \n",
              "707    0.731166   0.833851  \n",
              "709    1.000000   1.000000  \n",
              "710    0.756461   0.846127  \n",
              "716    0.816811   0.907602  \n",
              "725    0.660997   0.766846  \n",
              "\n",
              "[100 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42d22afe-fbfc-400c-b64b-3a9baafa6014\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sim</th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>sim01</th>\n",
              "      <th>sent1_punct</th>\n",
              "      <th>sent2_punct</th>\n",
              "      <th>sent1_stop</th>\n",
              "      <th>sent2_stop</th>\n",
              "      <th>google_sim</th>\n",
              "      <th>glove_sim</th>\n",
              "      <th>wmd_google</th>\n",
              "      <th>wmd_glove</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.2</td>\n",
              "      <td>He will stand trial on 8 January on charges of...</td>\n",
              "      <td>It passes in lawsuit next on January 8. It is ...</td>\n",
              "      <td>0.84</td>\n",
              "      <td>stand trial 8 january charges attended meeting...</td>\n",
              "      <td>passes lawsuit next january 8 reproached taken...</td>\n",
              "      <td>[stand, trial, 8, january, charges, attended, ...</td>\n",
              "      <td>[passes, lawsuit, next, january, 8, reproached...</td>\n",
              "      <td>0.923275</td>\n",
              "      <td>0.952771</td>\n",
              "      <td>0.690925</td>\n",
              "      <td>0.797823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.8</td>\n",
              "      <td>Mr President, the Commission' s attitude to th...</td>\n",
              "      <td>Mr President, we can see the Commission's posi...</td>\n",
              "      <td>0.96</td>\n",
              "      <td>mr president commission attitude right access ...</td>\n",
              "      <td>mr president see commission position terms pub...</td>\n",
              "      <td>[mr, president, commission, attitude, right, a...</td>\n",
              "      <td>[mr, president, see, commission, position, ter...</td>\n",
              "      <td>0.807435</td>\n",
              "      <td>0.992223</td>\n",
              "      <td>0.744582</td>\n",
              "      <td>0.852462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Fifty-seven senators, including 24 Republicans...</td>\n",
              "      <td>Of those who signed the letter, 57 are senator...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>fiftyseven senators including 24 republicans s...</td>\n",
              "      <td>signed letter 57 senators including 24 republi...</td>\n",
              "      <td>[fiftyseven, senators, including, 24, republic...</td>\n",
              "      <td>[signed, letter, 57, senators, including, 24, ...</td>\n",
              "      <td>0.518123</td>\n",
              "      <td>0.946429</td>\n",
              "      <td>0.875752</td>\n",
              "      <td>0.898666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.4</td>\n",
              "      <td>Reiterating the calls made by the European Par...</td>\n",
              "      <td>As the European Parliament, in its resolution ...</td>\n",
              "      <td>0.88</td>\n",
              "      <td>reiterating calls made european parliament res...</td>\n",
              "      <td>european parliament resolution 16 march 2000 i...</td>\n",
              "      <td>[reiterating, calls, made, european, parliamen...</td>\n",
              "      <td>[european, parliament, resolution, 16, march, ...</td>\n",
              "      <td>0.966281</td>\n",
              "      <td>0.991883</td>\n",
              "      <td>0.794706</td>\n",
              "      <td>0.897016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.0</td>\n",
              "      <td>As a matter of urgency, therefore, the staff c...</td>\n",
              "      <td>Therefore, it is urgent that the personnel of ...</td>\n",
              "      <td>0.80</td>\n",
              "      <td>matter urgency therefore staff complement inte...</td>\n",
              "      <td>therefore urgent personnel interservice group ...</td>\n",
              "      <td>[matter, urgency, therefore, staff, complement...</td>\n",
              "      <td>[therefore, urgent, personnel, interservice, g...</td>\n",
              "      <td>0.604373</td>\n",
              "      <td>0.940241</td>\n",
              "      <td>0.669141</td>\n",
              "      <td>0.747385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>707</th>\n",
              "      <td>3.8</td>\n",
              "      <td>He will stand trial on 8 January on charges of...</td>\n",
              "      <td>It happening in trial on 8 January. he is accu...</td>\n",
              "      <td>0.76</td>\n",
              "      <td>stand trial 8 january charges attended meeting...</td>\n",
              "      <td>happening trial 8 january accused taking part ...</td>\n",
              "      <td>[stand, trial, 8, january, charges, attended, ...</td>\n",
              "      <td>[happening, trial, 8, january, accused, taking...</td>\n",
              "      <td>0.949604</td>\n",
              "      <td>0.951461</td>\n",
              "      <td>0.731166</td>\n",
              "      <td>0.833851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Question No 6 by (H-0886/00):</td>\n",
              "      <td>Question No 6 by (H-0886/00):</td>\n",
              "      <td>1.00</td>\n",
              "      <td>question no 6 h088600</td>\n",
              "      <td>question no 6 h088600</td>\n",
              "      <td>[question, no, 6, h088600]</td>\n",
              "      <td>[question, no, 6, h088600]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>3.8</td>\n",
              "      <td>As long ago as 1996 the European Parliament ca...</td>\n",
              "      <td>In 1996, the European Parliament is in favour ...</td>\n",
              "      <td>0.76</td>\n",
              "      <td>long ago 1996 european parliament came favor b...</td>\n",
              "      <td>1996 european parliament favor ban use europea...</td>\n",
              "      <td>[long, ago, 1996, european, parliament, came, ...</td>\n",
              "      <td>[1996, european, parliament, favor, ban, use, ...</td>\n",
              "      <td>0.802647</td>\n",
              "      <td>0.969966</td>\n",
              "      <td>0.756461</td>\n",
              "      <td>0.846127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>4.4</td>\n",
              "      <td>Reiterating the calls made by the European Par...</td>\n",
              "      <td>As the European Parliament called for in its r...</td>\n",
              "      <td>0.88</td>\n",
              "      <td>reiterating calls made european parliament res...</td>\n",
              "      <td>european parliament called resolution 16 march...</td>\n",
              "      <td>[reiterating, calls, made, european, parliamen...</td>\n",
              "      <td>[european, parliament, called, resolution, 16,...</td>\n",
              "      <td>0.976658</td>\n",
              "      <td>0.993452</td>\n",
              "      <td>0.816811</td>\n",
              "      <td>0.907602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>3.6</td>\n",
              "      <td>He will stand trial on 8 January on charges of...</td>\n",
              "      <td>It crosses the 8 January of this year. it is t...</td>\n",
              "      <td>0.72</td>\n",
              "      <td>stand trial 8 january charges attended meeting...</td>\n",
              "      <td>crosses 8 january year union tunisian opponent...</td>\n",
              "      <td>[stand, trial, 8, january, charges, attended, ...</td>\n",
              "      <td>[crosses, 8, january, year, union, tunisian, o...</td>\n",
              "      <td>0.896926</td>\n",
              "      <td>0.893717</td>\n",
              "      <td>0.660997</td>\n",
              "      <td>0.766846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42d22afe-fbfc-400c-b64b-3a9baafa6014')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42d22afe-fbfc-400c-b64b-3a9baafa6014 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42d22afe-fbfc-400c-b64b-3a9baafa6014');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[92].sent1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Vqu3DdT23vW5",
        "outputId": "cddc3d0a-b9b0-41e7-88c9-1409869eac42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The broader Standard & Poor's 500 Index .SPX gained 3 points, or 0.39 percent, at 924.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[92].sent2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lkt87la-GBv2",
        "outputId": "62d1cde0-aa0c-48d8-b46d-a9da9b6351e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The technology-laced Nasdaq Composite Index <.IXIC> rose 6 points, or 0.41 percent, to 1,498.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R_PX7MvF6_MA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "add_numbers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}